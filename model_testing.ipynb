{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from io import StringIO\n",
    "import json\n",
    "import re\n",
    "import ast\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import pacf\n",
    "from sklearn.linear_model import LassoCV, RidgeCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from pmdarima.arima.utils import ndiffs\n",
    "import scipy.optimize as opt\n",
    "from functools import partial\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pulling In Log Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_log_file(file_path):\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "    \n",
    "    # Extract sections\n",
    "    sandbox_section = re.search(r'Sandbox logs:(.*?)Activities log:', content, re.DOTALL).group(1).strip()\n",
    "    activities_section = re.search(r'Activities log:(.*?)Trade History:', content, re.DOTALL).group(1).strip()\n",
    "    trade_section = re.search(r'Trade History:(.*?)$', content, re.DOTALL).group(1).strip()\n",
    "    \n",
    "    # Function to parse multi-line JSON objects\n",
    "    def extract_json_objects(json_string):\n",
    "        # Split the string into lines\n",
    "        lines = json_string.strip().split('\\n')\n",
    "        \n",
    "        # Initialize variables\n",
    "        json_objects = []\n",
    "        current_object = \"\"\n",
    "        inside_object = False\n",
    "        \n",
    "        for idx, line in enumerate(lines):\n",
    "            if line.strip().startswith('{'):\n",
    "                inside_object = True\n",
    "                current_object = line\n",
    "            elif line.strip().endswith('}') and inside_object:\n",
    "                current_object += line\n",
    "                json_objects.append(json.loads(current_object))\n",
    "                current_object = \"\"\n",
    "                inside_object = False\n",
    "            elif inside_object:\n",
    "                current_object += line\n",
    "        \n",
    "        return json_objects\n",
    "    \n",
    "    # Parse each section\n",
    "    sandbox_logs = extract_json_objects(sandbox_section)\n",
    "    activities_list = pd.read_csv(StringIO(activities_section), sep=';')\n",
    "    trade_list = ast.literal_eval(trade_section)\n",
    "\n",
    "    sandbox_dicts = {}\n",
    "    \n",
    "    own_trades_df = pd.DataFrame(columns=['symbol', 'price', 'quantity', 'buyer', 'seller', 'timestamp'])\n",
    "\n",
    "    market_trades_df = pd.DataFrame(columns=['symbol', 'price', 'quantity', 'buyer', 'seller', 'timestamp'])\n",
    "    \n",
    "    bid_df = pd.DataFrame(columns=['symbol','bid_price', 'bid_volume','timestamp'])\n",
    "    ask_df = pd.DataFrame(columns=['symbol','ask_price', 'ask_volume','timestamp'])\n",
    "\n",
    "    position_df = pd.DataFrame(columns=['symbol', 'position', 'timestamp'])\n",
    "\n",
    "    trader_orders_df = pd.DataFrame(columns=['timestamp', 'symbol', 'price', 'quantity', 'type'])\n",
    "    trader_data_df = pd.DataFrame(columns=['timestamp', 'symbol', 'orderbook_theo', 'signal_theo', 'return', 'residual', 'expected_return'])\n",
    "\n",
    "    timestamps  = list(range(0, 1 + (len(sandbox_logs) * 100), 100))\n",
    "\n",
    "    market_trade_info_df = pd.DataFrame(columns=['timestamp', 'symbol', 'average_weighted_price', 'total_volume'])\n",
    "    own_trade_info_df = pd.DataFrame(columns=['timestamp', 'symbol', 'average_weighted_price', 'total_volume'])\n",
    "\n",
    "    for log in sandbox_logs:\n",
    "\n",
    "        lambda_log = log['lambdaLog']\n",
    "        try:\n",
    "            if \"LATEST\\n\" in lambda_log and \"\\nEND\" in lambda_log:\n",
    "                start_idx = lambda_log.find(\"LATEST\\n\") + len(\"LATEST\\n\")\n",
    "                end_idx = lambda_log.find(\"\\nEND\")\n",
    "                \n",
    "                json_content = lambda_log[start_idx:end_idx]\n",
    "                parsed = json.loads(json_content)\n",
    "\n",
    "            else:\n",
    "                parsed = json.loads(lambda_log)\n",
    "\n",
    "        except:\n",
    "            raise Exception(\"Error parsing log\")\n",
    "        \n",
    "\n",
    "        sandbox_dicts[parsed['state']['timestamp']] = parsed\n",
    "\n",
    "        parsed_own_trades_df = pd.DataFrame(parsed['state'][\"own_trades\"], columns=['symbol', 'price', 'quantity', 'buyer', 'seller', 'timestamp'])\n",
    "\n",
    "        parsed_own_trades_df = parsed_own_trades_df[parsed_own_trades_df['timestamp']  == parsed['state']['timestamp']- 100]\n",
    "\n",
    "        if not parsed_own_trades_df.empty:\n",
    "            own_trades_df = pd.concat([own_trades_df, parsed_own_trades_df], ignore_index=True)\n",
    "            \n",
    "        parsed_market_trades_df = pd.DataFrame(parsed['state'][\"market_trades\"], columns=['symbol', 'price', 'quantity', 'buyer', 'seller', 'timestamp'])\n",
    "        \n",
    "        parsed_market_trades_df = parsed_market_trades_df[parsed_market_trades_df['timestamp']  == parsed['state']['timestamp']- 100]\n",
    "\n",
    "        if not parsed_market_trades_df.empty:\n",
    "            market_trades_df = pd.concat([market_trades_df, parsed_market_trades_df], ignore_index=True)\n",
    "\n",
    "        for symbol, depth in parsed['state']['order_depths'].items():\n",
    "\n",
    "            parsed_bid_df = pd.DataFrame(list(depth[0].items()), columns=['bid_price', 'bid_volume'])\n",
    "            parsed_ask_df = pd.DataFrame(list(depth[1].items()), columns=['ask_price', 'ask_volume'])\n",
    "\n",
    "            parsed_ask_df['ask_volume'] = np.abs(parsed_ask_df['ask_volume'])\n",
    "\n",
    "            parsed_bid_df['symbol'] = symbol\n",
    "            parsed_ask_df['symbol'] = symbol\n",
    "\n",
    "            parsed_bid_df['timestamp'] = parsed['state']['timestamp']\n",
    "            parsed_ask_df['timestamp'] = parsed['state']['timestamp']\n",
    "            \n",
    "            bid_df = pd.concat([bid_df, parsed_bid_df], ignore_index=True)\n",
    "            ask_df = pd.concat([ask_df, parsed_ask_df], ignore_index=True)\n",
    "\n",
    "        parsed_position_df = pd.DataFrame(list(parsed['state']['position'].items()), columns=['symbol', 'position'])\n",
    "\n",
    "        parsed_position_df['timestamp'] = parsed['state']['timestamp']\n",
    "\n",
    "        position_df = pd.concat([position_df, parsed_position_df], ignore_index=True)\n",
    "        \n",
    "        parsed_trader_data = json.loads(parsed['state']['trader_data'])\n",
    "\n",
    "        orders_df = pd.DataFrame(columns = ['symbol', 'price', 'quantity', 'type', 'order_type','offset_asked'])\n",
    "\n",
    "        symbol_list = list(parsed_trader_data['orderbook_theos'].keys())\n",
    "        info_df = pd.DataFrame({'symbol': symbol_list,\n",
    "                                     'orderbook_theo': [parsed_trader_data['orderbook_theos'][symbol][-1] for symbol in symbol_list],\n",
    "                                     'signal_theo': [parsed_trader_data['signal_theos'][symbol][-1] for symbol in symbol_list],\n",
    "                                        'return': [parsed_trader_data['return'][symbol][-1] for symbol in symbol_list],\n",
    "                                        'residual': [parsed_trader_data['residual'][symbol][-1] for symbol in symbol_list],\n",
    "                                        'expected_return': [parsed_trader_data['expected_return'][symbol] for symbol in symbol_list]\n",
    "                                        })\n",
    "        \n",
    "        info_df['timestamp'] = parsed['state']['timestamp']\n",
    "\n",
    "        market_trade_info_df = pd.concat([market_trade_info_df, pd.DataFrame({'timestamp': parsed['state']['timestamp'],\n",
    "                                             'symbol': list(parsed_trader_data['market_trades_data'].keys()),\n",
    "                                             'average_weighted_price': [values['average_weighted_price'] for values in parsed_trader_data['market_trades_data'].values()],\n",
    "                                             'total_volume': [values['total_volume'] for values in parsed_trader_data['market_trades_data'].values()],\n",
    "                                        })], ignore_index=True)\n",
    "        \n",
    "        own_trade_info_df = pd.concat([own_trade_info_df, pd.DataFrame({'timestamp': parsed['state']['timestamp'],\n",
    "                                        'symbol': list(parsed_trader_data['own_trades_data'].keys()),\n",
    "                                        'average_weighted_price': [values['average_weighted_price'] for values in parsed_trader_data['own_trades_data'].values()],\n",
    "                                        'total_volume': [values['total_volume'] for values in parsed_trader_data['own_trades_data'].values()],\n",
    "                                })], ignore_index=True)\n",
    "\n",
    "\n",
    "        for symbol in parsed_trader_data['maker_orders'].keys():\n",
    "            maker_orders_df = pd.DataFrame(parsed_trader_data['maker_orders'][symbol], columns=['symbol', 'price', 'quantity','offset_asked']) if len(parsed_trader_data['maker_orders'][symbol]) > 0 else pd.DataFrame(columns=['symbol', 'price', 'quantity','offset_asked'])\n",
    "            taker_orders_df = pd.DataFrame(parsed_trader_data['_taker_orders'][symbol], columns=['symbol', 'price', 'quantity']) if len(parsed_trader_data['_taker_orders'][symbol]) > 0 else pd.DataFrame(columns=['symbol', 'price', 'quantity'])\n",
    "\n",
    "            maker_orders_df['type'] = 'maker'\n",
    "            taker_orders_df['type'] = 'taker'\n",
    "            taker_orders_df['offset_asked'] = np.nan\n",
    "\n",
    "            dfs_to_concat = [df for df in [orders_df, maker_orders_df, taker_orders_df] if not df.empty]\n",
    "            if dfs_to_concat: \n",
    "                orders_df = pd.concat(dfs_to_concat, ignore_index=True)\n",
    "\n",
    "\n",
    "        orders_df['timestamp'] = parsed['state']['timestamp']\n",
    "    \n",
    "        if not info_df.empty:\n",
    "            trader_data_df = pd.concat([trader_data_df, info_df], ignore_index=True)\n",
    "        if not orders_df.empty:\n",
    "            trader_orders_df = pd.concat([trader_orders_df, orders_df], ignore_index=True)\n",
    "\n",
    "    trader_data_df = trader_data_df.groupby('symbol').apply(\n",
    "        lambda x: x.assign(**{'return': x['return'].shift(-1)})\n",
    "    ).sort_values('timestamp').reset_index(drop=True)\n",
    "    \n",
    "    trader_data_df['return'] = trader_data_df['return'].fillna(0)\n",
    "\n",
    "    market_trades_df = market_trades_df.sort_values('timestamp')\n",
    "    \n",
    "    symbols = position_df['symbol'].unique()\n",
    "\n",
    "    result_dfs = []\n",
    "\n",
    "    for symbol in symbols:\n",
    "        symbol_data = position_df[position_df['symbol'] == symbol]\n",
    "\n",
    "        symbol_all_times = pd.DataFrame({\n",
    "                'symbol': symbol,\n",
    "                'timestamp': timestamps\n",
    "            })\n",
    "        \n",
    "        symbol_merged = pd.merge(symbol_all_times, symbol_data, \n",
    "                                    on=['symbol', 'timestamp'], how='left')\n",
    "            \n",
    "        symbol_merged = symbol_merged.sort_values('timestamp')\n",
    "        symbol_merged['position'] = symbol_merged['position'].ffill().fillna(0).astype('float64')\n",
    "\n",
    "        result_dfs.append(symbol_merged)\n",
    "\n",
    "    position_df = pd.concat(result_dfs, ignore_index=True)\n",
    "\n",
    "    activities_df, trade_history_df = pd.DataFrame(activities_list), pd.DataFrame(trade_list)\n",
    "\n",
    "    # Conversion for market_trade_info_df\n",
    "    market_trade_info_df['timestamp'] = market_trade_info_df['timestamp'].astype(int)\n",
    "    market_trade_info_df['symbol'] = market_trade_info_df['symbol'].astype(str)\n",
    "    market_trade_info_df['average_weighted_price'] = market_trade_info_df['average_weighted_price'].astype(float)\n",
    "    market_trade_info_df['total_volume'] = market_trade_info_df['total_volume'].astype(int)\n",
    "\n",
    "    own_trade_info_df['timestamp'] = own_trade_info_df['timestamp'].astype(int)\n",
    "    own_trade_info_df['symbol'] = own_trade_info_df['symbol'].astype(str)\n",
    "    own_trade_info_df['average_weighted_price'] = own_trade_info_df['average_weighted_price'].astype(float)\n",
    "    own_trade_info_df['total_volume'] = own_trade_info_df['total_volume'].astype(int)\n",
    "\n",
    "    # Conversion for trader_orders_df\n",
    "    trader_orders_df['timestamp'] = trader_orders_df['timestamp'].astype(int)\n",
    "    trader_orders_df['symbol'] = trader_orders_df['symbol'].astype(str)\n",
    "    trader_orders_df['price'] = trader_orders_df['price'].astype(int)\n",
    "    trader_orders_df['quantity'] = trader_orders_df['quantity'].astype(int)\n",
    "    trader_orders_df['type'] = trader_orders_df['type'].astype(str)\n",
    "    # offset_asked is already float64\n",
    "\n",
    "    # Conversion for trader_data_df\n",
    "    trader_data_df['timestamp'] = trader_data_df['timestamp'].astype(int)\n",
    "    trader_data_df['symbol'] = trader_data_df['symbol'].astype(str)\n",
    "    trader_data_df['orderbook_theo'] = trader_data_df['orderbook_theo'].astype(float)\n",
    "    trader_data_df['signal_theo'] = trader_data_df['signal_theo'].astype(float)\n",
    "\n",
    "    # Conversion for position_df\n",
    "    position_df['symbol'] = position_df['symbol'].astype(str)\n",
    "    position_df['timestamp'] = position_df['timestamp'].astype(int)\n",
    "    # position is already float64\n",
    "\n",
    "    # Conversion for bid_df\n",
    "    bid_df['symbol'] = bid_df['symbol'].astype(str)\n",
    "    bid_df['bid_price'] = bid_df['bid_price'].astype(int)\n",
    "    bid_df['bid_volume'] = bid_df['bid_volume'].astype(int)\n",
    "    bid_df['timestamp'] = bid_df['timestamp'].astype(int)\n",
    "\n",
    "    # Conversion for ask_df\n",
    "    ask_df['symbol'] = ask_df['symbol'].astype(str)\n",
    "    ask_df['ask_price'] = ask_df['ask_price'].astype(int)\n",
    "    ask_df['ask_volume'] = ask_df['ask_volume'].astype(int)\n",
    "    ask_df['timestamp'] = ask_df['timestamp'].astype(int)\n",
    "\n",
    "    # Conversion for own_trades_df\n",
    "    own_trades_df['symbol'] = own_trades_df['symbol'].astype(str)\n",
    "    # price is already float64\n",
    "    own_trades_df['quantity'] = own_trades_df['quantity'].astype(int)\n",
    "    own_trades_df['buyer'] = own_trades_df['buyer'].astype(str)\n",
    "    own_trades_df['seller'] = own_trades_df['seller'].astype(str)\n",
    "    own_trades_df['timestamp'] = own_trades_df['timestamp'].astype(int)\n",
    "\n",
    "    # Conversion for market_trades_df\n",
    "    market_trades_df['symbol'] = market_trades_df['symbol'].astype(str)\n",
    "    # price is already float64\n",
    "    market_trades_df['quantity'] = market_trades_df['quantity'].astype(int)\n",
    "    market_trades_df['buyer'] = market_trades_df['buyer'].astype(str)\n",
    "    market_trades_df['seller'] = market_trades_df['seller'].astype(str)\n",
    "    market_trades_df['timestamp'] = market_trades_df['timestamp'].astype(int)\n",
    "\n",
    "    activities_df['product'] = activities_df['product'].astype(str)\n",
    "\n",
    "    trade_history_df['buyer'] = trade_history_df['buyer'].astype(str)\n",
    "    trade_history_df['seller'] = trade_history_df['seller'].astype(str)\n",
    "    trade_history_df['symbol'] = trade_history_df['symbol'].astype(str)\n",
    "    trade_history_df['currency'] = trade_history_df['currency'].astype(str)\n",
    "\n",
    "    return sandbox_dicts, market_trade_info_df, own_trade_info_df, trader_orders_df, trader_data_df, position_df, bid_df, ask_df, own_trades_df, market_trades_df,  activities_df, trade_history_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file_path = \"C://Users//marco//Downloads//6d902f9a-0384-4028-bd0a-5d7f80eb878c.log\"\n",
    "\n",
    "sandbox_dicts, market_trade_info_df, own_trade_info_df, trader_orders_df, trader_data_df, position_df, bid_df, ask_df, own_trades_df, market_trades_df,  activities_df, trade_history_df = parse_log_file(log_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of All of the Dataframes\n",
    "\n",
    "1.   market_trade_info_df: average weighted price, total_volume traded of market trades during timestamp\n",
    "\n",
    "        We receive information about these trades in run() at timestamp t + 100\n",
    "\n",
    "2.   own_trade_info_df: average weighted price, total_volume traded of own trades during timestamp\n",
    "\n",
    "        We receive information about these trades in run() at timestamp t + 100\n",
    "\n",
    "3.   trader_orders_df: timestamp, price, quantity, type of order (maker or taker), and offset demanded if maker\n",
    "\n",
    "        Explaining Offset Demanded:\n",
    "        - If the trader is a maker, the offset demanded is (Edge of Order Price to Theo) / (Std of Price Return)\n",
    "\n",
    "4.   trader_data_df: timestamp, symbol, orderbook_theo, signal_theo, return, residual, expected_return\n",
    "\n",
    "5.   position_df: current position at timestamp t\n",
    "\n",
    "6.   bid_df: symbol, bid price, volume, timestamp\n",
    "\n",
    "7.   ask_df: symbol, ask price, volume, timestamp\n",
    "\n",
    "8.   own_trades_df: symbol, price, quantity, buyer, seller, timestamp\n",
    "\n",
    "9.   market_trades_df: symbol, price, quantity, buyer, seller, timestamp\n",
    "\n",
    "9.   activities_df: day, timestamp, product, Top 3 Order Book Levels, mid_price, profit_and_loss\n",
    "\n",
    "10.  trade_history_df: market_trades_df + own_trades_df\n",
    "\n",
    "### Sandbox Dictionary\n",
    "\n",
    "1.   Parsed Dictionary From JSON\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Theo = f(Orderbook, Market Trades, Own Trades)\n",
    "\n",
    "Our goal is to generate a theo that is as close as possible to imc_theo_(t+1). We want every single trade we make to mark in as well as possible.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_position_trajectory_with_pnl(own_trades: pd.DataFrame) -> pd.DataFrame:\n",
    "    trades_sorted = own_trades.sort_values(by=\"timestamp\").copy()\n",
    "    pos_records = [{\n",
    "            \"timestamp\": 0,\n",
    "            \"product\": product,\n",
    "            \"position\": 0,\n",
    "            \"cost_basis\": np.nan,\n",
    "            \"realized_pnl\": np.nan,\n",
    "            \"realized_pnl_cum\": np.nan,\n",
    "        } for product in own_trades['symbol'].unique()]\n",
    "    \n",
    "    # Track state by product\n",
    "    state = {}\n",
    "    \n",
    "\n",
    "    for _, row in trades_sorted.iterrows():\n",
    "        product = row[\"symbol\"]\n",
    "        t = row[\"timestamp\"]\n",
    "        qty = row[\"quantity\"]\n",
    "        px = row[\"price\"]\n",
    "        \n",
    "        # Determine if we're buying or selling\n",
    "        if row[\"buyer\"] == \"SUBMISSION\":\n",
    "            delta_pos = +qty  # We're buying\n",
    "        elif row[\"seller\"] == \"SUBMISSION\":\n",
    "            delta_pos = -qty  # We're selling\n",
    "        else:\n",
    "            continue  # Not our trade\n",
    "        \n",
    "        # Initialize state for this product if not seen before\n",
    "        if product not in state:\n",
    "            state[product] = {\n",
    "                \"pos\": 0.0,\n",
    "                \"cost_basis\": 0.0,\n",
    "                \"realized_cum\": 0.0\n",
    "            }\n",
    "        \n",
    "        old_pos = state[product][\"pos\"]\n",
    "        old_cb = state[product][\"cost_basis\"]\n",
    "        old_realized = state[product][\"realized_cum\"]\n",
    "                \n",
    "        # Determine if we're opening, increasing, reducing, or closing a position\n",
    "        if abs(old_pos) < 1e-10:  # No existing position\n",
    "        # Opening a new position\n",
    "            new_pos = delta_pos\n",
    "            new_cb = px\n",
    "            trade_realized = 0.0\n",
    "        elif (old_pos > 0 and delta_pos > 0) or (old_pos < 0 and delta_pos < 0):\n",
    "            total_pos = old_pos + delta_pos\n",
    "            new_cb = (old_pos * old_cb + delta_pos * px) / total_pos\n",
    "            new_pos = total_pos\n",
    "            trade_realized = 0.0\n",
    "        elif (old_pos > 0 and delta_pos < 0) or (old_pos < 0 and delta_pos > 0):\n",
    "            # Trade in opposite direction of position\n",
    "            # First determine if we're reducing or flipping the position\n",
    "            if abs(delta_pos) <= abs(old_pos):\n",
    "                # Reducing position\n",
    "                trade_realized = -delta_pos * (px - old_cb) if old_pos > 0 else delta_pos * (old_cb - px)\n",
    "                \n",
    "                new_pos = old_pos + delta_pos\n",
    "                new_cb = old_cb  # Cost basis stays the same when reducing\n",
    "            else:\n",
    "\n",
    "                # Flipping position (close existing and open new in opposite direction)\n",
    "                # Calculate PnL on the closed portion\n",
    "                trade_realized = old_pos * (px - old_cb) if old_pos > 0 else -old_pos * (old_cb - px)\n",
    "                # # Remaining quantity becomes a new position\n",
    "                new_pos = old_pos + delta_pos\n",
    "                new_cb = px  # New cost basis is this trade's price\n",
    "            \n",
    "\n",
    "        # Update cumulative realized PnL\n",
    "        new_realized_cum = old_realized + trade_realized\n",
    "        \n",
    "        # Clean up tiny values due to floating point issues\n",
    "        if abs(new_pos) < 1e-10:\n",
    "            new_pos = 0.0\n",
    "            new_cb = 0.0\n",
    "        \n",
    "        # Update state\n",
    "        state[product][\"pos\"] = new_pos\n",
    "        state[product][\"cost_basis\"] = new_cb\n",
    "        state[product][\"realized_cum\"] = new_realized_cum\n",
    "        \n",
    "        # Record this position update\n",
    "        pos_records.append({\n",
    "            \"timestamp\": t + 100,\n",
    "            \"product\": product,\n",
    "            \"position\": new_pos,\n",
    "            \"cost_basis\": new_cb,\n",
    "            \"realized_pnl\": trade_realized,\n",
    "            \"realized_pnl_cum\": new_realized_cum\n",
    "        })\n",
    "    \n",
    "    position_df = pd.DataFrame(pos_records)\n",
    "    \n",
    "    position_df = (\n",
    "        position_df\n",
    "        .sort_values([\"product\", \"timestamp\"])\n",
    "        .groupby([\"product\", \"timestamp\"], as_index=False)\n",
    "        .last()\n",
    "    )\n",
    "    \n",
    "    return position_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def microprice_theo(symbol, timestamp, bid_df, ask_df, market_trade_info_df, own_trade_info_df, betas) -> float:\n",
    "\n",
    "    bid_df_selected, ask_df_selected = bid_df[(bid_df['symbol'] == symbol) & (bid_df['timestamp'] == timestamp)], ask_df[(ask_df['symbol'] == symbol) & (ask_df['timestamp'] == timestamp)]\n",
    "    own_trade_info_df_selected = own_trade_info_df[(own_trade_info_df['symbol'] == symbol) & (own_trade_info_df['timestamp'] == timestamp)]\n",
    "    market_trade_info_df_selected = market_trade_info_df[(market_trade_info_df['symbol'] == symbol) & (market_trade_info_df['timestamp'] == timestamp)]\n",
    "\n",
    "    bid_prices = bid_df_selected['bid_price'].values\n",
    "    bid_volumes = bid_df_selected['bid_volume'].values\n",
    "    ask_prices = ask_df_selected['ask_price'].values\n",
    "    ask_volumes = ask_df_selected['ask_volume'].values\n",
    "\n",
    "    own_volume, own_average_price = own_trade_info_df_selected['total_volume'].values[0], own_trade_info_df_selected['average_weighted_price'].values[0]\n",
    "    market_volume, market_average_price = market_trade_info_df_selected['total_volume'].values[0], market_trade_info_df_selected['average_weighted_price'].values[0]\n",
    "\n",
    "    if len(bid_volumes) == 0 or len(ask_volumes) == 0 or max(bid_volumes) == 0 or max(ask_volumes) == 0:\n",
    "        return np.nan\n",
    "\n",
    "    level_weights = np.array([1] + betas[:-2])\n",
    "\n",
    "    own_trades_weight, market_trades_weight = betas[-2:]\n",
    "\n",
    "    bid_levels = []\n",
    "\n",
    "    for idx_bid in range(min(len(bid_prices), len(level_weights))):\n",
    "        if pd.notna(bid_prices[idx_bid]) and pd.notna(bid_volumes[idx_bid]) and bid_volumes[idx_bid]>0:\n",
    "            bid_levels.append((bid_prices[idx_bid], bid_volumes[idx_bid] * level_weights[idx_bid]))\n",
    "\n",
    "    total_bid_vol = sum(x[1] for x in bid_levels)\n",
    "    weighted_bid  = sum(x[0]*x[1] for x in bid_levels) / total_bid_vol\n",
    "\n",
    "    ask_levels = []\n",
    "\n",
    "    for idx_ask in range(min(len(ask_prices), len(level_weights))):\n",
    "        if pd.notna(ask_prices[idx_ask]) and pd.notna(ask_volumes[idx_ask]) and ask_volumes[idx_ask]>0:\n",
    "            ask_levels.append((ask_prices[idx_ask], ask_volumes[idx_ask] * level_weights[idx_ask]))\n",
    "\n",
    "    total_ask_vol = sum(x[1] for x in ask_levels)\n",
    "    weighted_ask  = sum(x[0]*x[1] for x in ask_levels) / total_ask_vol\n",
    "\n",
    "    weighted_own_vol = own_volume * own_trades_weight\n",
    "    weighted_market_vol = market_volume * market_trades_weight\n",
    "    weighted_own_average_price = own_average_price * weighted_own_vol if weighted_own_vol > 0 else 0\n",
    "    weighted_market_average_price = market_average_price * weighted_market_vol if weighted_market_vol > 0 else 0\n",
    "\n",
    "    total_vol = total_bid_vol + total_ask_vol + weighted_own_vol + weighted_market_vol\n",
    "    if total_vol < 1e-9:\n",
    "        return np.nan\n",
    "    \n",
    "    microprice = (weighted_ask * total_bid_vol + weighted_bid * total_ask_vol + weighted_own_average_price + weighted_market_average_price) / total_vol\n",
    "\n",
    "    return microprice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_predicted_pnl(\n",
    "    symbol: str,\n",
    "    position_steps: pd.DataFrame,\n",
    "    activities_df: pd.DataFrame,\n",
    "    betas: tuple\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    act_df = activities_df.copy()\n",
    "\n",
    "    act_df = act_df.sort_values([\"product\", \"timestamp\"], ascending=[True, True])\n",
    "    position_steps = position_steps.sort_values([\"product\", \"timestamp\"], ascending=[True, True])\n",
    "\n",
    "    merged = pd.merge(\n",
    "        act_df,\n",
    "        position_steps,\n",
    "        on=[\"product\",\"timestamp\"],\n",
    "        how = \"left\"\n",
    "    )\n",
    "    \n",
    "    merged[\"position\"]   = merged[\"position\"].ffill().fillna(0.0)\n",
    "    merged[\"cost_basis\"] = merged[\"cost_basis\"].ffill().fillna(0.0)\n",
    "    merged[\"realized_pnl\"] = merged[\"realized_pnl\"].ffill().fillna(0.0)\n",
    "    merged[\"realized_pnl_cum\"] = merged[\"realized_pnl_cum\"].ffill().fillna(0.0)\n",
    "\n",
    "    merged[\"theo_price\"] = merged.apply(lambda x: microprice_theo(symbol, x['timestamp'], bid_df, ask_df, market_trade_info_df, own_trade_info_df, betas), axis=1)\n",
    "    merged[\"imc_theo\"] =  merged['cost_basis'] + ((merged['profit_and_loss'] - merged['realized_pnl_cum']) / merged['position'])\n",
    "\n",
    "    merged['imc_theo'].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "    merged['imc_theo'] = merged['imc_theo'].ffill()\n",
    "\n",
    "    merged[\"error_theo\"] = merged[\"imc_theo\"] - merged[\"theo_price\"]\n",
    "\n",
    "    return merged "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_pnl(position_steps, activities_df, own_trades, betas, verbose=False):\n",
    "\n",
    "    df = compute_predicted_pnl(position_steps, activities_df, own_trades, betas)\n",
    "\n",
    "    if verbose:\n",
    "        print(betas)\n",
    "\n",
    "    mse = np.mean(df[~np.isnan(df['error_theo'])][\"error_theo\"]**2)\n",
    "\n",
    "    return df, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(betas, position_pnl_df, activities_df, own_trades_df, verbose=False):\n",
    "\n",
    "    _, mse_val = mse_pnl(\n",
    "        position_pnl_df,\n",
    "        activities_df,\n",
    "        own_trades_df,\n",
    "        betas,\n",
    "        verbose=verbose\n",
    "    )\n",
    "    \n",
    "    return mse_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = own_trades_df['symbol'].unique()\n",
    "timestamps = list(sorted(activities_df['timestamp'].unique()))\n",
    "\n",
    "position_pnl_df = build_position_trajectory_with_pnl(own_trades_df)\n",
    "\n",
    "result_dfs = []\n",
    "\n",
    "for symbol in symbols:\n",
    "\n",
    "    symbol_data = position_pnl_df[position_pnl_df['product'] ==  symbol]\n",
    "\n",
    "    symbol_all_times = pd.DataFrame({\n",
    "            'product': symbol,\n",
    "            'timestamp': timestamps\n",
    "        })\n",
    "    \n",
    "    symbol_merged = pd.merge(symbol_all_times, symbol_data, \n",
    "                                on=['product', 'timestamp'], how='left')\n",
    "        \n",
    "    symbol_merged = symbol_merged.sort_values('timestamp')\n",
    "    symbol_merged['position'] = symbol_merged['position'].ffill().fillna(0).astype('float64')\n",
    "\n",
    "    result_dfs.append(symbol_merged)\n",
    "\n",
    "position_df = pd.concat(result_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_guess = (1, 1, 1, 1)\n",
    "\n",
    "bounds = [(0, 2)]*4\n",
    "\n",
    "betas = {}\n",
    "cleaned_theos = {}\n",
    "\n",
    "for product in position_df['product'].unique():\n",
    "\n",
    "    init_mse = objective(init_guess,\n",
    "                         position_pnl_df[position_pnl_df['product'] == product],\n",
    "                         activities_df[activities_df['product'] == product],\n",
    "                         own_trades_df[own_trades_df['symbol'] == product])\n",
    "    \n",
    "    product_objective = partial(objective,\n",
    "                               position_pnl_df = position_pnl_df[position_pnl_df['product'] == product],\n",
    "                               activities_df = activities_df[activities_df['product'] == product],\n",
    "                               own_trades_df = own_trades_df[own_trades_df['symbol'] == product],\n",
    "                               verbose=False)\n",
    "    \n",
    "\n",
    "    result = opt.minimize(\n",
    "        product_objective,\n",
    "        x0=init_guess,\n",
    "        method='SLSQP',\n",
    "        bounds=bounds,\n",
    "        options={\"eps\": 1e-4}\n",
    "    )\n",
    "\n",
    "    mse_df, mse_val = mse_pnl(\n",
    "        position_df[position_df['product'] == product],\n",
    "        activities_df[activities_df['product'] == product],\n",
    "        own_trades_df[own_trades_df['symbol'] == product],\n",
    "        result.x,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    cleaned_theos[product] = mse_df[['timestamp', 'theo_price','imc_theo']].copy()\n",
    "\n",
    "    cleaned_theos[product].loc[:, 'return_theo'] = cleaned_theos[product]['theo_price'].pct_change().shift(-1).fillna(0)\n",
    "    cleaned_theos[product].loc[:, 'return_mtm'] = (cleaned_theos[product]['imc_theo'].shift(-1) / cleaned_theos[product]['theo_price']) - 1\n",
    "\n",
    "    cleaned_theos[product].loc[:, 'next_imc_theo'] = cleaned_theos[product]['imc_theo'].shift(-1)\n",
    "\n",
    "    print(f\"Optimization result for product {product}:\", result)\n",
    "    print(f\"Best betas for product {product}:\", result.x)\n",
    "    print(f\"Initial MSE for product {product}:\", init_mse)\n",
    "    print(f\"MSE for product {product}:\", result.fun)\n",
    "    betas[product] = result.x\n",
    "\n",
    "\n",
    "cleaned_theos_df = pd.concat(cleaned_theos.values(), ignore_index=True)1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signal Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HAR Regression Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA Regression Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing For P and Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production Quoting Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examining Quantity Filled\n",
    "\n",
    "maker_orders = trader_orders_df[trader_orders_df['type'] == 'maker'].copy()\n",
    "\n",
    "buy_trades = own_trades_df[own_trades_df['buyer'] == 'SUBMISSION'].copy()\n",
    "sell_trades = own_trades_df[own_trades_df['seller'] == 'SUBMISSION'].copy()\n",
    "\n",
    "trader_orders_df['quantity_filled'] = 0\n",
    "\n",
    "maker_orders['original_index'] = maker_orders.index\n",
    "\n",
    "buy_merged = maker_orders[maker_orders['quantity'] > 0].merge(\n",
    "    buy_trades,\n",
    "    on=['timestamp', 'price', 'symbol'],\n",
    "    how='left',\n",
    "    suffixes=('', '_trade')\n",
    ")\n",
    "\n",
    "sell_merged = maker_orders[maker_orders['quantity'] < 0].merge(\n",
    "    sell_trades,\n",
    "    on=['timestamp', 'price', 'symbol'],\n",
    "    how='left',\n",
    "    suffixes=('', '_trade')\n",
    ")\n",
    "\n",
    "filled_orders = pd.concat([buy_merged, sell_merged])\n",
    "\n",
    "trader_orders_df.loc[filled_orders['original_index'], 'quantity_filled'] = filled_orders['quantity_trade']\n",
    "\n",
    "trader_orders_df.drop(columns=['original_index'], inplace=True)\n",
    "\n",
    "trader_orders_df['quantity_filled'] = trader_orders_df['quantity_filled'].fillna(0)\n",
    "\n",
    "# Examining 1 Tick Markout\n",
    "\n",
    "trader_orders_df = trader_orders_df.merge(cleaned_theos_df[['timestamp', 'symbol', 'next_imc_theo']], on=['timestamp', 'symbol'], how='left').merge(trader_data_df[['timestamp', 'symbol', 'signal_theo']], on=['timestamp', 'symbol'], how='left')\n",
    "\n",
    "filled_orders = trader_orders_df[trader_orders_df['quantity_filled'] > 0]\n",
    "\n",
    "filled_orders['expected_edge_per_contract'] = np.where(filled_orders['buyer_trade'] == 'SUBMISSION', filled_orders['signal_theo'] - filled_orders['price'], filled_orders['price'] - filled_orders['signal_theo'])\n",
    "filled_orders['retained_edge_per_contract'] = np.where(filled_orders['buyer_trade'] == 'SUBMISSION', filled_orders['next_imc_theo'] - filled_orders['price'], filled_orders['price'] - filled_orders['next_imc_theo'])\n",
    "\n",
    "filled_orders['expected_edge'] = filled_orders['expected_edge_per_contract'] * filled_orders['quantity_filled']\n",
    "filled_orders['retained_edge'] = filled_orders['retained_edge_per_contract'] * filled_orders['quantity_filled']\n",
    "\n",
    "filled_orders['fill_percentage'] = filled_orders['quantity_filled'] / filled_orders['quantity']\n",
    "\n",
    "filled_orders['offset_bucket'] = pd.cut(filled_orders['offset_asked'], bins=[-np.inf, 0, 0.5, 1, 1.5, 2, np.inf], labels=['-', '0-0.5', '0.5-1', '1-1.5', '1.5-2', '2+'])\n",
    "filled_orders['fill_percentage_bucket'] = pd.cut(filled_orders['fill_percentage'], bins=[-np.inf, 0.3, 0.8, 1], labels=['0-0.3', '0.3-0.8', '0.8-1'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge Retained Statistics\n",
    "\n",
    "For every product, we want to calculate the following statistics:\n",
    "1.   Cash Edge, Percentage of Edge Retained Over 1 Tick\n",
    "2.   Cash Edge, Percentage of Edge Retained By Offset Bucket [(0, 0.5), (0.5, 1), (1, 1.5), (1.5, 2), (2+)]\n",
    "3.   Cash Edge, Percentage of Edge Retained Over Fill Percentage Bucket [(0, 0.3), (0.3, 0.8), (0.8, 1)] And Offset Bucket [(0, 1), (1, 2), (2+)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cash Edge Retained Over 1 Tick\n",
    "\n",
    "cash_edge_retained_summary = filled_orders.groupby(['symbol']).agg({\n",
    "    'retained_edge': 'sum',\n",
    "    'expected_edge': 'sum'\n",
    "})\n",
    "\n",
    "display(cash_edge_retained_summary)\n",
    "\n",
    "# Percentage of Edge Retained Over 1 Tick\n",
    "\n",
    "percentage_edge_retained_summary = pd.DataFrame({'percentage_retained': cash_edge_retained_summary['retained_edge'] / cash_edge_retained_summary['expected_edge']})\n",
    "\n",
    "display(percentage_edge_retained_summary)\n",
    "\n",
    "# Cash Edge Retained By Offset Bucket\n",
    "\n",
    "cash_edge_retained_offset_summary = filled_orders.groupby(['symbol', 'offset_bucket']).agg({\n",
    "    'retained_edge': 'sum',\n",
    "    'expected_edge': 'sum'\n",
    "})\n",
    "\n",
    "display(cash_edge_retained_offset_summary)\n",
    "\n",
    "# Percentage of Edge Retained By Offset Bucket\n",
    "\n",
    "percentage_edge_retained_offset_summary = pd.DataFrame({'percentage_retained': cash_edge_retained_offset_summary['retained_edge'] / cash_edge_retained_offset_summary['expected_edge']})\n",
    "\n",
    "display(percentage_edge_retained_offset_summary)\n",
    "\n",
    "# Cash Edge Retained Over Fill Percentage Bucket And Offset Bucket\n",
    "\n",
    "cash_edge_retained_offset_fill_summary = filled_orders.groupby(['symbol', 'offset_bucket', 'fill_percentage_bucket']).agg({\n",
    "    'retained_edge': 'sum',\n",
    "    'expected_edge': 'sum'\n",
    "})\n",
    "\n",
    "display(cash_edge_retained_offset_fill_summary)\n",
    "\n",
    "# Percentage of Edge Retained Over Fill Percentage Bucket And Offset Bucket\n",
    "\n",
    "percentage_edge_retained_offset_fill_summary = pd.DataFrame({'percentage_retained': cash_edge_retained_offset_fill_summary['retained_edge'] / cash_edge_retained_offset_fill_summary['expected_edge']})\n",
    "\n",
    "display(percentage_edge_retained_offset_fill_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autocorrelation of Trade Direction\n",
    "\n",
    "Given dPos_maker(t), we want correlation of dPos_maker(t) with dPos_maker(t-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production Taking Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking Opportunities, How Many Do We Capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(np.mean(rainforest_resin_df['weighted_midprice_level_1'].shift(1) < rainforest_resin_df['bid_price_1']))\n",
    "print(np.mean(rainforest_resin_df['weighted_midprice_level_1'].shift(1) > rainforest_resin_df['ask_price_1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OOS Signal / Return Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for symbol in trader_data_df['symbol'].unique():\n",
    "    symbol_mask = trader_data_df['symbol'] == symbol\n",
    "    X = trader_data_df[symbol_mask][['expected_return']]\n",
    "    y = trader_data_df[symbol_mask]['return'].fillna(0)\n",
    "    signal_model = sm.OLS(y, sm.add_constant(X)).fit()\n",
    "    print(f\"Symbol: {symbol}, R-squared: {signal_model.rsquared}, Correlation: {signal_model.rsquared ** 0.5}, Beta: {signal_model.params[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Expected Return vs Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_symbols = len(trader_data_df['symbol'].unique())\n",
    "\n",
    "fig, axes = plt.subplots(1, n_symbols, figsize=(5*n_symbols, 5), sharey=True)\n",
    "\n",
    "if n_symbols == 1:\n",
    "    axes = np.array([axes])\n",
    "\n",
    "for i, symbol in enumerate(trader_data_df['symbol'].unique()):\n",
    "    symbol_mask = trader_data_df['symbol'] == symbol\n",
    "\n",
    "    axes[i].scatter(trader_data_df[symbol_mask]['expected_return'], trader_data_df[symbol_mask]['return'])\n",
    "\n",
    "    min_val, max_val = min(trader_data_df[symbol_mask]['expected_return']), max(trader_data_df[symbol_mask]['expected_return']) \n",
    "\n",
    "    axes[i].plot([min_val, max_val], [min_val, max_val], 'r-')\n",
    "    axes[i].set_title(f'{symbol} Signal vs Return')\n",
    "    axes[i].set_xlabel('Expected Return')\n",
    "    axes[i].set_ylabel('Return')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge Retention Analysis - Taking Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inventory Management\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_symbols = len(trader_data_df['symbol'].unique())\n",
    "\n",
    "fig, axes = plt.subplots(1, n_symbols, figsize=(5*n_symbols, 5), sharey=True)\n",
    "\n",
    "if n_symbols == 1:\n",
    "    axes = np.array([axes])\n",
    "\n",
    "for i, symbol in enumerate(trader_data_df['symbol'].unique()):\n",
    "    symbol_mask = trader_data_df['symbol'] == symbol\n",
    "\n",
    "    axes[i].scatter(trader_data_df[symbol_mask]['expected_return'], trader_data_df[symbol_mask]['return'])\n",
    "\n",
    "    min_val, max_val = min(trader_data_df[symbol_mask]['expected_return']), max(trader_data_df[symbol_mask]['expected_return']) \n",
    "\n",
    "    axes[i].plot([min_val, max_val], [min_val, max_val], 'r-')\n",
    "    axes[i].set_title(f'{symbol} Signal vs Return')\n",
    "    axes[i].set_xlabel('Expected Return')\n",
    "    axes[i].set_ylabel('Return')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Position And PnL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itables\n",
    "import itables.options as opt\n",
    "opt.precision = 8 \n",
    "itables.show(own_trades_df)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
